{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from allennlp.data.token_indexers import PretrainedTransformerMismatchedIndexer\n",
    "# import jsonpickle\n",
    "# a= PretrainedTransformerMismatchedIndexer(\"distilbert-base-uncased\")\n",
    "# a_pickled = jsonpickle.dumps(a)\n",
    "# b = jsonpickle.loads(a_pickled)\n",
    "# b._tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d92b7bb84e248e39b6d495a6e5c296b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='reading instances', max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c2410b0c544665987a77ff9d5c6957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='caching instances', max=50.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b14cf13a9e94729a3cdffbe81ad1278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='building vocab', max=50.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[“CUDA_DEVICE_ORDER”]=“PCI_BUS_ID”\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "# experiment_name = \"3_heads_lr3_keep_op_identity+agenda_enriched_all+lr_e3+mult_scalar_per_action+glove\"\n",
    "# experiment_name = \"crappy-red-dhole\"\n",
    "# train_dataset = reader.read(\"dataset/train_spider.json\")\n",
    "from models.semantic_parsing.ratsql_encoder import RatsqlEncoder\n",
    "# from models.semantic_parsing.gnn_encoder import GnnEncoder\n",
    "from models.semantic_parsing.spider_decoder import SpiderParser\n",
    "from allennlp.modules.seq2vec_encoders.boe_encoder import BagOfEmbeddingsEncoder\n",
    "\n",
    "from allennlp.modules.attention import DotProductAttention\n",
    "from allennlp.nn.beam_search import BeamSearch\n",
    "from allennlp.modules.seq2seq_encoders.pass_through_encoder import PassThroughEncoder\n",
    "\n",
    "\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "\n",
    "import torch.optim as optim\n",
    "from allennlp.training.trainer import Trainer\n",
    "import torch\n",
    "from allennlp.models.archival import Archive\n",
    "import torch\n",
    "from allennlp.common import Params\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.common.params import with_fallback\n",
    "from dataset_readers.spider_ratsql import SpiderRatsqlDatasetReader\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "\n",
    "\n",
    "# from models.semantic_parsing.spider_parser import SpiderParser\n",
    "# reader = SpiderRatsqlDatasetReader(tables_file=\"dataset/tables.json\",max_instances=None)\n",
    "reader = SpiderRatsqlDatasetReader(tables_file=\"dataset/tables.json\",max_instances=50)\n",
    "# settings = Params.from_file(f\"experiments/{experiment_name}/config.json\")\n",
    "# model = Model.load(config=settings, serialization_dir=f\"experiments/{experiment_name}\")\n",
    "\n",
    "\n",
    "train_dataset = reader.read(\"dataset/train_spider.json\")\n",
    "vocab = Vocabulary.from_instances(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with torch.cuda.device(0):\n",
    "EMBEDDING_DIM = 768\n",
    "HIDDEN_DIM = 768\n",
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=EMBEDDING_DIM)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "\n",
    "\n",
    "beam = BeamSearch(end_index=0,beam_size=10)\n",
    "\n",
    "schema_encoder = RatsqlEncoder(encoder=PassThroughEncoder(768),entity_encoder=BagOfEmbeddingsEncoder(768),question_embedder=word_embeddings,action_embedding_dim=768)\n",
    "# schema_encoder = GnnEncoder(encoder=PassThroughEncoder(200),entity_encoder=BagOfEmbeddingsEncoder(200),question_embedder=word_embeddings,action_embedding_dim=200)\n",
    "model = SpiderParser(vocab=vocab,schema_encoder=schema_encoder, \n",
    "                     decoder_beam_search=beam,input_attention=DotProductAttention(),past_attention=DotProductAttention(),max_decoding_steps=10)\n",
    "\n",
    "model.cuda()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17, 768])\n",
      "torch.Size([1, 17, 768])\n",
      "[{'loss': 24.333939}]\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17, 768])\n",
      "torch.Size([1, 17, 768])\n",
      "[{'loss': 45.600105}]\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17, 768])\n",
      "torch.Size([1, 17, 768])\n",
      "[{'loss': 23.701244}]\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17, 768])\n",
      "torch.Size([1, 17, 768])\n",
      "[{'loss': 19.844234}]\n",
      "torch.Size([1, 18])\n",
      "torch.Size([1, 18])\n",
      "torch.Size([1, 18, 768])\n",
      "torch.Size([1, 18, 768])\n",
      "[{'loss': 31.630465}]\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17, 768])\n",
      "torch.Size([1, 17, 768])\n",
      "[{'loss': 26.500357}]\n",
      "torch.Size([1, 19])\n",
      "torch.Size([1, 19])\n",
      "torch.Size([1, 19, 768])\n",
      "torch.Size([1, 19, 768])\n",
      "[{'loss': 66.02926}]\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17, 768])\n",
      "torch.Size([1, 17, 768])\n",
      "[{'loss': 65.110756}]\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17, 768])\n",
      "torch.Size([1, 17, 768])\n",
      "[{'loss': 25.729002}]\n",
      "torch.Size([1, 21])\n",
      "torch.Size([1, 21])\n",
      "torch.Size([1, 21, 768])\n",
      "torch.Size([1, 21, 768])\n",
      "[{'loss': 53.16741}]\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17, 768])\n",
      "torch.Size([1, 17, 768])\n",
      "[{'loss': 20.716225}]\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17, 768])\n",
      "torch.Size([1, 17, 768])\n",
      "[{'loss': 52.357613}]\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17, 768])\n",
      "torch.Size([1, 17, 768])\n",
      "[{'loss': 28.22327}]\n",
      "torch.Size([1, 21])\n",
      "torch.Size([1, 21])\n",
      "torch.Size([1, 21, 768])\n",
      "torch.Size([1, 21, 768])\n",
      "[{'loss': 120.065475}]\n",
      "torch.Size([1, 22])\n",
      "torch.Size([1, 22])\n",
      "torch.Size([1, 22, 768])\n",
      "torch.Size([1, 22, 768])\n",
      "[{'loss': 61.46701}]\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17])\n",
      "torch.Size([1, 17, 768])\n",
      "torch.Size([1, 17, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7f51839e03f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_on_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/specific_ohadr/netapp5/joberant/home/ohadr/.conda/cap/lib/python3.7/site-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36mforward_on_instances\u001b[0;34m(self, instances)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_output_human_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             instance_separated_output: List[Dict[str, numpy.ndarray]] = [\n",
      "\u001b[0;32m/mnt/specific_ohadr/netapp5/joberant/home/ohadr/.conda/cap/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2020A/spider-schema-gnn-global/models/semantic_parsing/spider_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, valid_actions, world, utterance, schema, action_sequence, enc, relation, schema_strings, lengths, offsets)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 decode_output = self._decoder_trainer.decode(initial_state,\n\u001b[1;32m    150\u001b[0m                                                              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transition_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                                                              (action_sequence.unsqueeze(1), action_mask.unsqueeze(1)))\n\u001b[0m\u001b[1;32m    152\u001b[0m                 \u001b[0mquery_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/specific_ohadr/netapp5/joberant/home/ohadr/.conda/cap/lib/python3.7/site-packages/allennlp_semparse/state_machines/trainers/maximum_marginal_likelihood.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, initial_state, transition_function, supervision)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mbeam_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConstrainedBeamSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_beam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         finished_states: Dict[int, List[State]] = beam_search.search(\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/specific_ohadr/netapp5/joberant/home/ohadr/.conda/cap/lib/python3.7/site-packages/allennlp_semparse/state_machines/constrained_beam_search.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, initial_state, transition_function)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 )\n\u001b[1;32m     97\u001b[0m             for next_state in transition_function.take_step(\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mgrouped_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_per_node_beam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             ):\n\u001b[1;32m    100\u001b[0m                 \u001b[0;31m# NOTE: we're doing state.batch_indices[0] here (and similar things below),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2020A/spider-schema-gnn-global/state_machines/transition_functions/attend_past_schema_items_transition.py\u001b[0m in \u001b[0;36mtake_step\u001b[0;34m(self, state, max_actions, allowed_actions)\u001b[0m\n\u001b[1;32m     68\u001b[0m                                                  \u001b[0mbatch_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                                                  \u001b[0mmax_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                                                  allowed_actions)\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2020A/spider-schema-gnn-global/state_machines/transition_functions/attend_past_schema_items_transition.py\u001b[0m in \u001b[0;36m_construct_next_states\u001b[0;34m(self, state, updated_rnn_state, batch_action_probs, max_actions, allowed_actions)\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_log_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0maction_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_action_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0mlog_probs_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                 batch_states = [(log_probs_cpu[i],\n\u001b[1;32m    353\u001b[0m                                  \u001b[0mgroup_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "a=None\n",
    "for inst in train_dataset:\n",
    "    a = inst\n",
    "    res_list = model.forward_on_instances([inst])\n",
    "    print(res_list)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator = BasicIterator(batch_size=15)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# iterator.index_with(vocab)\n",
    "# trainer = Trainer(model=model,\n",
    "#                   optimizer=optimizer,\n",
    "#                   iterator=iterator,\n",
    "#                   train_dataset=train_dataset,\n",
    "#                   validation_dataset=train_dataset,\n",
    "#                   patience=10,\n",
    "#                   num_epochs=1)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'schema_strings': <allennlp.data.fields.metadata_field.MetadataField at 0x7f03629b8290>,\n",
       " 'enc': <allennlp.data.fields.text_field.TextField at 0x7f0381e34780>,\n",
       " 'lengths': <allennlp.data.fields.array_field.ArrayField at 0x7f0381e34960>,\n",
       " 'offsets': <allennlp.data.fields.array_field.ArrayField at 0x7f037d74fc30>,\n",
       " 'relation': <allennlp.data.fields.array_field.ArrayField at 0x7f0381e34910>,\n",
       " 'valid_actions': <allennlp.data.fields.list_field.ListField at 0x7f03629f8090>,\n",
       " 'action_sequence': <allennlp.data.fields.list_field.ListField at 0x7f03629b84d0>,\n",
       " 'world': <allennlp.data.fields.metadata_field.MetadataField at 0x7f03629959d0>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fields    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import  allennlp.nn.util as util\n",
    "import torch\n",
    "\n",
    "def batched_span_select(target: torch.Tensor, spans: torch.LongTensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    The given `spans` of size `(batch_size, num_spans, 2)` indexes into the sequence\n",
    "    dimension (dimension 2) of the target, which has size `(batch_size, sequence_length,\n",
    "    embedding_size)`.\n",
    "    This function returns segmented spans in the target with respect to the provided span indices.\n",
    "    It does not guarantee element order within each span.\n",
    "    # Parameters\n",
    "    target : `torch.Tensor`, required.\n",
    "        A 3 dimensional tensor of shape (batch_size, sequence_length, embedding_size).\n",
    "        This is the tensor to be indexed.\n",
    "    indices : `torch.LongTensor`\n",
    "        A 3 dimensional tensor of shape (batch_size, num_spans, 2) representing start and end\n",
    "        indices (both inclusive) into the `sequence_length` dimension of the `target` tensor.\n",
    "    # Returns\n",
    "    span_embeddings : `torch.Tensor`\n",
    "        A tensor with shape (batch_size, num_spans, max_batch_span_width, embedding_size]\n",
    "        representing the embedded spans extracted from the batch flattened target tensor.\n",
    "    span_mask: `torch.BoolTensor`\n",
    "        A tensor with shape (batch_size, num_spans, max_batch_span_width) representing the mask on\n",
    "        the returned span embeddings.\n",
    "    \"\"\"\n",
    "    # both of shape (batch_size, num_spans, 1)\n",
    "    span_starts, span_ends = spans.split(1, dim=-1)\n",
    "\n",
    "    # shape (batch_size, num_spans, 1)\n",
    "    # These span widths are off by 1, because the span ends are `inclusive`.\n",
    "    span_widths = span_ends - span_starts\n",
    "\n",
    "    # We need to know the maximum span width so we can\n",
    "    # generate indices to extract the spans from the sequence tensor.\n",
    "    # These indices will then get masked below, such that if the length\n",
    "    # of a given span is smaller than the max, the rest of the values\n",
    "    # are masked.\n",
    "    max_batch_span_width = span_widths.max().item() + 1\n",
    "\n",
    "    # Shape: (1, 1, max_batch_span_width)\n",
    "    max_span_range_indices = util.get_range_vector(max_batch_span_width, util.get_device_of(target)).view(\n",
    "        1, 1, -1\n",
    "    )\n",
    "#     print(max_batch_span_width)\n",
    "#     print(max_span_range_indices)\n",
    "    # Shape: (batch_size, num_spans, max_batch_span_width)\n",
    "    # This is a broadcasted comparison - for each span we are considering,\n",
    "    # we are creating a range vector of size max_span_width, but masking values\n",
    "    # which are greater than the actual length of the span.\n",
    "    #\n",
    "    # We're using <= here (and for the mask below) because the span ends are\n",
    "    # inclusive, so we want to include indices which are equal to span_widths rather\n",
    "    # than using it as a non-inclusive upper bound.\n",
    "    span_mask = max_span_range_indices <= span_widths\n",
    "#     raw_span_indices = span_ends - max_span_range_indices\n",
    "    raw_span_indices = span_starts + max_span_range_indices\n",
    "#     print(raw_span_indices)\n",
    "#     print(target.size())\n",
    "    # We also don't want to include span indices which are less than zero,\n",
    "    # which happens because some spans near the beginning of the sequence\n",
    "    # have an end index < max_batch_span_width, so we add this to the mask here.\n",
    "    span_mask = span_mask & (raw_span_indices < target.size(1))\n",
    "#     print(span_mask)\n",
    "#     span_indices = torch.nn.functional.relu(raw_span_indices.float()).long()\n",
    "    span_indices = raw_span_indices * span_mask\n",
    "#     print(span_indices)\n",
    "    \n",
    "    # Shape: (batch_size, num_spans, max_batch_span_width, embedding_dim)\n",
    "    span_embeddings = util.batched_index_select(target, span_indices)\n",
    "\n",
    "    return span_embeddings, span_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0],\n",
      "         [ 1],\n",
      "         [ 2],\n",
      "         [ 3],\n",
      "         [ 4],\n",
      "         [ 5],\n",
      "         [ 6],\n",
      "         [ 7],\n",
      "         [ 8],\n",
      "         [ 9],\n",
      "         [10],\n",
      "         [11],\n",
      "         [12],\n",
      "         [13],\n",
      "         [14]],\n",
      "\n",
      "        [[15],\n",
      "         [16],\n",
      "         [17],\n",
      "         [18],\n",
      "         [19],\n",
      "         [20],\n",
      "         [21],\n",
      "         [22],\n",
      "         [23],\n",
      "         [24],\n",
      "         [25],\n",
      "         [26],\n",
      "         [27],\n",
      "         [28],\n",
      "         [29]],\n",
      "\n",
      "        [[30],\n",
      "         [31],\n",
      "         [32],\n",
      "         [33],\n",
      "         [34],\n",
      "         [35],\n",
      "         [36],\n",
      "         [37],\n",
      "         [38],\n",
      "         [39],\n",
      "         [40],\n",
      "         [41],\n",
      "         [42],\n",
      "         [43],\n",
      "         [44]]])\n",
      "tensor([[0, 1],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# torch.tensor\n",
    "a = util.get_range_vector(45,-1).reshape([3,15,1])\n",
    "print(a)\n",
    "q = 2\n",
    "t = 3\n",
    "b = torch.tensor([[0,q-1],[q,q+t-1]])\n",
    "# b = torch.tensor([[[1,3]],[[2,3]],[[3,4]]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0],\n",
       "           [1],\n",
       "           [0]],\n",
       " \n",
       "          [[2],\n",
       "           [3],\n",
       "           [4]]]]),\n",
       " tensor([[[ True,  True, False],\n",
       "          [ True,  True,  True]]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_span_select(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[1],\n",
       "           [0],\n",
       "           [0]],\n",
       " \n",
       "          [[4],\n",
       "           [3],\n",
       "           [2]]]]),\n",
       " tensor([[[ True,  True, False],\n",
       "          [ True,  True,  True]]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.batched_span_select(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'fields'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-85339ef0d6ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# list()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'enc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lengths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'fields'"
     ]
    }
   ],
   "source": [
    "# list()\n",
    "import numpy as np\n",
    "b = a.fields['enc']\n",
    "token_ids = [0]+b.tokens\n",
    "c = a.fields['lengths'].array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0]+token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = b.tokens[0]\n",
    "# vars(y)\n",
    "y.text_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(c.array)\n",
    "offsets = get_offsets(c)\n",
    "res = [token_ids[offsets[j][0]:offsets[j][1] + 1] for j in range(len(offsets))]\n",
    "# print(res)\n",
    "# print()\n",
    "# for x in [[vocab.get_token_from_index(y,\"tags\") for y in x] for x in res]:\n",
    "for x in res:\n",
    "    print([y.text_id for y in x])\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Size([1, 205, 2])\n",
    "torch.Size([1, 205, 768])\n",
    "tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 16, 13, 12, 12, 12, 14, 14,\n",
    "         13, 12, 13, 12, 13, 13, 13,  4,  4,  4]], dtype=torch.int32) torch.Size([1, 28])\n",
    "tensor([2129])\n",
    "tensor([2116])\n",
    "tensor([4641])\n",
    "tensor([1997])\n",
    "tensor([1996])\n",
    "tensor([7640])\n",
    "tensor([2024])\n",
    "tensor([3080])\n",
    "tensor([2084])\n",
    "tensor([5179])\n",
    "tensor([1029])\n",
    "tensor([ 1026,  2828,  1024,  3793,  1028,  1008,  1026,  2795,  1011, 19802,\n",
    "         1028,  1026,  2151,  1011,  2795,  1028])\n",
    "tensor([ 1026,  2828,  1024,  2193,  1028,  2533,  8909,  1026,  2795,  1011,\n",
    "        19802,  1028,  2533])\n",
    "tensor([ 1026,  2828,  1024,  3793,  1028,  2171,  1026,  2795,  1011, 19802,\n",
    "         1028,  2533])\n",
    "tensor([ 1026,  2828,  1024,  3793,  1028,  4325,  1026,  2795,  1011, 19802,\n",
    "         1028,  2533])\n",
    "tensor([ 1026,  2828,  1024,  2193,  1028,  5464,  1026,  2795,  1011, 19802,\n",
    "         1028,  2533])\n",
    "tensor([ 1026,  2828,  1024,  2193,  1028,  5166,  1999, 25501,  1026,  2795,\n",
    "         1011, 19802,  1028,  2533])\n",
    "tensor([ 1026,  2828,  1024,  2193,  1028, 16371,  1001,  1001,  1049,  5126,\n",
    "         1026,  2795,  1011, 19802])\n",
    "tensor([ 1028,  2533,  1026,  2828,  1024,  2193,  1028,  2132,  8909,  1026,\n",
    "         2795,  1011, 19802])\n",
    "tensor([ 1028,  2132,  1026,  2828,  1024,  3793,  1028,  2171,  1026,  2795,\n",
    "         1011, 19802])\n",
    "tensor([ 1028,  2132,  1026,  2828,  1024,  3793,  1028,  2141,  2110,  1026,\n",
    "         2795,  1011, 19802])\n",
    "tensor([ 1028,  2132,  1026,  2828,  1024,  2193,  1028,  2287,  1026,  2795,\n",
    "         1011, 19802])\n",
    "tensor([ 1028,  2132,  1026,  2828,  1024,  2193,  1028,  2533,  8909,  1026,\n",
    "         2795,  1011, 19802])\n",
    "tensor([ 1028,  2968,  1026,  2828,  1024,  2193,  1028,  2132,  8909,  1026,\n",
    "         2795,  1011, 19802])\n",
    "tensor([ 1028,  2968,  1026,  2828,  1024,  3793,  1028,  5741,  3772,  1026,\n",
    "         2795,  1011, 19802])\n",
    "tensor([1028, 2968, 1026, 2795])\n",
    "tensor([1028, 2533, 1026, 2795])\n",
    "tensor([1028, 2132, 1026, 2795])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=None\n",
    "for inst in train_dataset:\n",
    "    a = inst\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary.from_instances(train_dataset)\n",
    "b=a.fields['enc']\n",
    "b.index(vocab)\n",
    "tok_dict = b._indexed_tokens['tokens']\n",
    "print(len(tok_dict['token_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "c=a.fields['lengths'].array\n",
    "token_ids = tok_dict['token_ids']\n",
    "old_offsets = tok_dict['offsets']\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_str = lambda x: [vocab.get_token_from_index(y,\"tags\") for y in x]\n",
    "lengths = np.array(list(c))+1\n",
    "# offsets = np.cumsum(lengths-1)\n",
    "# offsets\n",
    "# print(lengths)\n",
    "\n",
    "# offsets = list(zip(offsets,offsets)\n",
    "# offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_ = \n",
    "# b_=offsets+lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_offsets(lengths):\n",
    "    e = np.cumsum(([0]+list(lengths))[:-1])\n",
    "    return list(zip(e+1,e+np.array(lengths)))\n",
    "\n",
    "offsets = get_offsets(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _token_indexers\n",
    "# to_str = lambda x: vocab.get_token_from_index(x,\"tags\")\n",
    "# print(c.array)\n",
    "res = [token_ids[offsets[j][0]:offsets[j][1] + 1] for j in range(len(offsets))]\n",
    "# print(res)\n",
    "# print()\n",
    "for x in [[vocab.get_token_from_index(y,\"tags\") for y in x] for x in res]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.get_token_from_index(102,'tags')\n",
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= b._token_indexers['tokens']\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.indices_to_tokens([23],vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward_on_instances([a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "i=random.randint(0,len(train_dataset))\n",
    "a=None\n",
    "for inst in train_dataset[i:i+1]:\n",
    "    a = inst\n",
    "    res_list = model.forward_on_instances([inst])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.fields['desc'].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= res_list[0]['initial_state']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= b.get_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.get_valid_actions()\n",
    "b.possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "i=random.randint(0,len(train_dataset))\n",
    "a=None\n",
    "for inst in train_dataset[i:i+1]:\n",
    "#     print(inst)\n",
    "    a=inst\n",
    "# b=a.fields['relation']\n",
    "# b.array\n",
    "b=a.fields['world']\n",
    "c=a.fields['desc']\n",
    "d=a.fields['item'] \n",
    "e = a.fields[\"schema\"]\n",
    "# b\n",
    "# print(a.fields['utterance'])\n",
    "for entity in b.metadata.db_context.knowledge_graph.entities:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in (c.metadata['columns']+c.metadata['tables']):\n",
    "def normalize_schema_constant(entity):\n",
    "#     print(entity)\n",
    "    col = \"_\".join(entity)\n",
    "    col =  col.split(\"_<table-sep>_\")\n",
    "    if len(col)==1:\n",
    "        return \"_\".join(entity)\n",
    "#         print()\n",
    "    else:\n",
    "        table = col[1]\n",
    "        col = col[0].split(\">_\")[1]\n",
    "        return f\"{table}@{col}\"\n",
    "#         print()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.entity_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.fields['valid_actions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.metadata.schema.columns[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"asdas_adsdas\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataset_readers.ratsql_spider_bert import *\n",
    "\n",
    "# builder = RelationBuilder()\n",
    "\n",
    "\n",
    "db_path = \"dataset/database\"\n",
    "pre = SpiderEncoderV2Preproc()\n",
    "schemas, eval_foreign_key_maps = pre.load_tables([\"dataset/tables.json\"])\n",
    "# for path in paths:\n",
    "for db_id, schema in tqdm(schemas.items(), desc=\"DB connections\"):\n",
    "    sqlite_path = Path(db_path) / db_id / f\"{db_id}.sqlite\"\n",
    "    source: sqlite3.Connection\n",
    "    with sqlite3.connect(sqlite_path) as source:\n",
    "        dest = sqlite3.connect(':memory:')\n",
    "        dest.row_factory = sqlite3.Row\n",
    "        source.backup(dest)\n",
    "    schema.connection = dest\n",
    "    \n",
    "examples=[]\n",
    "raw_data = json.load(open(\"dataset/train_spider.json\"))\n",
    "for entry in raw_data:\n",
    "    item = SpiderItem(\n",
    "        text=entry['question_toks'],\n",
    "        code=entry['sql'],\n",
    "        schema=schemas[entry['db_id']],\n",
    "        orig=entry,\n",
    "        orig_schema=schemas[entry['db_id']].orig)\n",
    "#     desc = pre.preprocess_item(item,\"train\")\n",
    "    examples.append(item)\n",
    "\n",
    "        # Backup in-memory copies of all the DBs and create the live connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples\n",
    "# \n",
    "import pandas as pd\n",
    "print \n",
    "# \n",
    "import tqdm\n",
    "for item in tqdm.tqdm(examples):\n",
    "    desc = pre.preprocess_item(item,\"train\")\n",
    "    q = desc['question']\n",
    "    q_len = len(q)\n",
    "    t = [x[0] for x in  desc['tables']]\n",
    "    t_len = len(t)\n",
    "    c = [\"_\".join(x) for x in  desc['columns']]\n",
    "    c_len = len(c)\n",
    "    enc = q+c+t\n",
    "    print(enc)\n",
    "    relation = pre.compute_relations(desc,len(enc),q_len,c_len,range(c_len+1),range(t_len+1))\n",
    "#     with np.printoptions(threshold=np.inf):\n",
    "#     print(np.array2string())\n",
    "\n",
    "    arr = pd.DataFrame(relation)\n",
    "#     print()\n",
    "    break\n",
    "# arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in a.items():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.fields['utterance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.sequence_length()\n",
    "b.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=a.fields['schema']\n",
    "c.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.compute_relations(dict(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.to_csv(\"t.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
